{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9141b10d-b8ac-4e02-ae0b-f45a6e135e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e634a76c-7fc4-4657-a329-429bdbec3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the number of papers\n",
    "\n",
    "import json\n",
    "\n",
    "input_file_path = 'peersum_all.json'\n",
    "output_file_path = 'output_file.json'\n",
    "\n",
    "def extract_and_write_first_5001_rows(input_file_path, output_file_path):\n",
    "    extracted_data = []\n",
    "    with open(input_file_path, 'r') as input_file:\n",
    "        for line in input_file:\n",
    "            try:\n",
    "                json_data = json.loads(line)\n",
    "                extracted_data.append(json_data)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping invalid JSON: {line.strip()}\")\n",
    "    \n",
    "    first_5001_rows = extracted_data[:1700]\n",
    "    \n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        json.dump(first_5001_rows, output_file, indent=4)\n",
    "\n",
    "extract_and_write_first_5001_rows(input_file_path, output_file_path)\n",
    "\n",
    "print(f\"The first 5001 rows have been extracted and written to '{output_file_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cee04eb2-e917-415e-9a8c-36420e862ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Converting to CSV for better readability\n",
    "import json\n",
    "import csv\n",
    "\n",
    "with open('output_file.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "filtered_reviews = []\n",
    "\n",
    "for item in data:\n",
    "    paper_id = item['paper_id']\n",
    "    paper_title = item['paper_title']\n",
    "    paper_acceptance = item['paper_acceptance']\n",
    "    reviews = item['reviews']\n",
    "    \n",
    "    \n",
    "    for review in reviews:\n",
    "        if review['writer'] == 'official_reviewer':\n",
    "            review_id = review['review_id']\n",
    "            comment = review['comment'].replace('\\n', ' ')\n",
    "            rating = review['rating']\n",
    "            confidence = review['confidence']\n",
    "            writer = review['writer']\n",
    "            \n",
    "            \n",
    "            \n",
    "            filtered_reviews.append([paper_id, paper_title, paper_acceptance, review_id, comment, rating, confidence, writer])\n",
    "\n",
    "with open('filtered_reviews.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, escapechar='\\\\')\n",
    "    \n",
    "    csv_writer.writerow(['paper_id', 'paper_title', 'paper_acceptance', 'review_id', 'comment', 'rating', 'confidence', 'writer'])\n",
    "    \n",
    "    csv_writer.writerows(filtered_reviews)\n",
    "\n",
    "print(\"CSV file has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "debafc8d-afbc-4624-8ae0-d9e33c95635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved to 'final_reviews.csv'\n"
     ]
    }
   ],
   "source": [
    "# Filtering out the non official comments\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('filtered_reviews.csv')\n",
    "\n",
    "filtered_df = df[~((df['confidence'] == 1) & (df['rating'] == 1)) &\n",
    "                 ~((df['confidence'] == 1) & (df['rating'] == -1)) &\n",
    "                 ~((df['confidence'] == -1) & (df['rating'] == 1)) &\n",
    "                 ~((df['confidence'] == -1) & (df['rating'] == -1))]\n",
    "\n",
    "filtered_df.to_csv('final_reviews.csv', index=False)\n",
    "\n",
    "print(\"Filtered data has been saved to 'final_reviews.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29b35c9b-eba3-4967-821a-82a2e8fc7dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"meta_reviews.csv\" created successfully.\n"
     ]
    }
   ],
   "source": [
    "#meta reviews generation\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "with open('output_file.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "csv_file_name = 'meta_reviews.csv'\n",
    "\n",
    "with open(csv_file_name, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    csv_writer.writerow(['paper_id', 'meta_review'])\n",
    "\n",
    "    for row in data:\n",
    "        paper_id = row.get('paper_id', '')\n",
    "        meta_review = row.get('meta_review', '')\n",
    "        csv_writer.writerow([paper_id, meta_review])\n",
    "\n",
    "print(f'CSV file \"{csv_file_name}\" created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2ddd64a-b1f4-4360-854b-a30a92e74325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "280f452c-21eb-4cfb-9c61-ca499c2dd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting it back to Json\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "filtered_reviews = pd.read_csv('filtered_reviews.csv')\n",
    "meta_reviews = pd.read_csv('meta_reviews.csv')\n",
    "\n",
    "merged_data = pd.merge(filtered_reviews, meta_reviews, on='paper_id')\n",
    "\n",
    "json_data = {}\n",
    "\n",
    "for index, row in merged_data.iterrows():\n",
    "    paper_id = row['paper_id']\n",
    "    if paper_id not in json_data:\n",
    "        json_data[paper_id] = {\n",
    "            'paper_title': row['paper_title'],\n",
    "            'paper_acceptance': row['paper_acceptance'],\n",
    "            'meta_review': row['meta_review'],\n",
    "            'reviews': []\n",
    "        }\n",
    "    \n",
    "    if row['rating'] != -1 and row['confidence'] != -1:\n",
    "        review = {\n",
    "            'review_id': row['review_id'],\n",
    "            'comment': row['comment'],\n",
    "            'rating': row['rating'],\n",
    "            'confidence': row['confidence'],\n",
    "            'writer': row['writer']\n",
    "        }\n",
    "        json_data[paper_id]['reviews'].append(review)\n",
    "\n",
    "json_output = json.dumps(list(json_data.values()), indent=2)\n",
    "\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "049f1134-2d0d-4a63-b029-1b3b8cb3fe0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6907281f-a4df-492e-8b82-e34bf8b83876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in the 'comment' column: 2872196\n"
     ]
    }
   ],
   "source": [
    "#token count\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string using GPT-4 tokenization.\"\"\"\n",
    "    num_tokens = len(enc.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def num_tokens_from_json(json_file_path: str) -> int:\n",
    "    \"\"\"Returns the total number of tokens in 'meta_review' and 'comment' fields of a JSON file.\"\"\"\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    total_tokens = 0\n",
    "\n",
    "    for entry in data:\n",
    "        meta_review_tokens = num_tokens_from_string(entry['meta_review'])\n",
    "        total_tokens += meta_review_tokens\n",
    "\n",
    "        for review in entry['reviews']:\n",
    "            comment_tokens = num_tokens_from_string(review['comment'])\n",
    "            total_tokens += comment_tokens\n",
    "\n",
    "    return total_tokens\n",
    "\n",
    "json_file_path = 'output.json'\n",
    "\n",
    "total_tokens_in_json = num_tokens_from_json(json_file_path)\n",
    "print(f\"Total tokens in the JSON file: {total_tokens_in_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a84c8e7f-fcd0-449b-80bc-659a780a8fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews based on review_id: 5166\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('output.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "total_reviews = 0\n",
    "\n",
    "for paper in data:\n",
    "    total_reviews += len(paper['reviews'])\n",
    "\n",
    "print(f'Total number of reviews based on review_id: {total_reviews}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f7fce-854d-4176-b9a7-2acb9600120f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
