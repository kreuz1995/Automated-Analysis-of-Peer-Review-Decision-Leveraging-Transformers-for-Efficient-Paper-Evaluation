{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e76167c-b749-46e4-8eac-a990470a6ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==0.23.0\n",
      "  Downloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting peft==0.5.0\n",
      "  Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting bitsandbytes==0.41.1\n",
      "  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting transformers==4.31\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting trl==0.7.2\n",
      "  Downloading trl-0.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting torch==2.0.0\n",
      "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.23.0) (6.0.1)\n",
      "Collecting huggingface-hub (from accelerate==0.23.0)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tqdm (from peft==0.5.0)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors (from peft==0.5.0)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (3.9.0)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.31)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting datasets (from trl==0.7.2)\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tyro>=0.5.7 (from trl==0.7.2)\n",
      "  Downloading tyro-0.8.2-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.0)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (68.2.2)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.41.3)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.0)\n",
      "  Downloading cmake-3.29.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
      "  Downloading lit-18.1.2.tar.gz (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/161.0 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting protobuf>=3.20 (from tensorboardX)\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub->accelerate==0.23.0)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.7->trl==0.7.2)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-extensions (from torch==2.0.0)\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1.0 (from tyro>=0.5.7->trl==0.7.2)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.7->trl==0.7.2)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pyarrow>=12.0.0 (from datasets->trl==0.7.2)\n",
      "  Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->trl==0.7.2)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->trl==0.7.2)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets->trl==0.7.2)\n",
      "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting xxhash (from datasets->trl==0.7.2)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->trl==0.7.2)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub->accelerate==0.23.0)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets->trl==0.7.2)\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->trl==0.7.2)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.2) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->trl==0.7.2)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->trl==0.7.2)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->trl==0.7.2)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets->trl==0.7.2)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro>=0.5.7->trl==0.7.2)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl==0.7.2) (2.16.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.7.2) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets->trl==0.7.2)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets->trl==0.7.2)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.7->trl==0.7.2)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.2) (1.16.0)\n",
      "Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m171.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.7.2-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m173.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m149.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m183.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m170.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.8.2-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m136.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m130.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading cmake-3.29.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m182.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-18.1.2-py3-none-any.whl size=96368 sha256=4376be22a4b085975b7ba2ee1202c472bd04c6b2c7c8a6d3f153ffa2ed716c80\n",
      "  Stored in directory: /root/.cache/pip/wheels/f4/4d/9c/3e28d23c2c6fc6a9bd89c91a7b7ff775fc71a41ac9a52563e9\n",
      "Successfully built lit\n",
      "Installing collected packages: tokenizers, pytz, lit, bitsandbytes, xxhash, tzdata, typing-extensions, tqdm, threadpoolctl, shtab, scipy, safetensors, regex, pyarrow-hotfix, pyarrow, protobuf, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, multidict, mdurl, joblib, fsspec, frozenlist, docstring-parser, dill, cmake, async-timeout, yarl, tensorboardX, scikit-learn, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, multiprocess, markdown-it-py, huggingface-hub, aiosignal, transformers, rich, aiohttp, tyro, datasets, triton, torch, accelerate, trl, peft\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.23.0 aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 bitsandbytes-0.41.1 cmake-3.29.0.1 datasets-2.18.0 dill-0.3.8 docstring-parser-0.16 frozenlist-1.4.1 fsspec-2024.2.0 huggingface-hub-0.22.2 joblib-1.3.2 lit-18.1.2 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.0.5 multiprocess-0.70.16 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pandas-2.2.1 peft-0.5.0 protobuf-5.26.1 pyarrow-15.0.2 pyarrow-hotfix-0.6 pytz-2024.1 regex-2023.12.25 rich-13.7.1 safetensors-0.4.2 scikit-learn-1.4.1.post1 scipy-1.13.0 shtab-1.7.1 tensorboardX-2.6.2.2 threadpoolctl-3.4.0 tokenizers-0.13.3 torch-2.0.0 tqdm-4.66.2 transformers-4.31.0 triton-2.0.0 trl-0.7.2 typing-extensions-4.11.0 tyro-0.8.2 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U accelerate==0.23.0 peft==0.5.0 bitsandbytes==0.41.1 transformers==4.31 trl==0.7.2 torch==2.0.0 tensorboardX scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016f72f2-2dff-441c-96cd-963ca67575e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b5b5b5-e769-41f4-aa22-e188fc807666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6161aeb9-9596-43c7-8783-ba9dd4ec68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "640389f2-235b-4705-9296-ad4c481a4bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "print(f\"pytorch version {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a536c328-c586-497b-9209-bd283c29712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from datasets import Dataset\n",
    "\n",
    "# # Assuming you have separate CSV files for train and test datasets\n",
    "# train_filename = \"train.csv\"\n",
    "# test_filename = \"test.csv\"\n",
    "\n",
    "# # Read the train and test datasets\n",
    "# train = pd.read_csv(train_filename, names=[\"sentiment\", \"text\",\"year\",\"id\"], encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "# test = pd.read_csv(test_filename, names=[\"sentiment\", \"text\",\"year\",\"id\"], encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "\n",
    "# # Split train dataset into train and validation sets\n",
    "# train_data, eval_data = train_test_split(train, train_size=0.95, test_size=0.05, random_state=42)\n",
    "\n",
    "\n",
    "# def generate_prompt(data_point):\n",
    "#     return f\"\"\"\n",
    "#              <INST>Consider yourself the meta reviewer of a conference. I will give you the review of a peer reviewer on a paper enclosed within <p> and </p>, and the  meta review of that particular review enclosed within <m> and </m>, that will carry the sentiment of the rating by the reviewer about that paper. Your job is to analyze both of them and output, whether the final decision of the reviwer on that paper will be Accept or Reject. Your output can be either Accept or Reject and no other text. No Revise or Resubmit. Do not print any extra text.Either Accept or Reject.</INST>\n",
    "            \n",
    "#             [{data_point[\"text\"]}] = {data_point[\"sentiment\"]}\n",
    "#             \"\"\".strip()\n",
    "\n",
    "# def generate_test_prompt(data_point):\n",
    "#     return f\"\"\"\n",
    "#             <INST>Consider yourself the meta reviewer of a conference. I will give you the review of a peer reviewer on a paper enclosed within <p> and </p>, and the  meta review of that particular review enclosed within <m> and </m>, that will carry the sentiment of the rating by the reviewer about that paper. Your job is to analyze both of them and output, whether the final decision of the reviwer on that paper will be Accept or Reject. Your output can be either Accept or Reject and no other text. No Revise or Resubmit. Do not print any extra text.Either Accept or Reject.</INST>\n",
    "\n",
    "#             [{data_point[\"text\"]}] = \"\"\".strip()\n",
    "\n",
    "# # Use train and test DataFrames as needed\n",
    "# X_train = pd.DataFrame(train.apply(generate_prompt, axis=1), columns=[\"text\"])\n",
    "# X_eval = pd.DataFrame(eval_data.apply(generate_prompt, axis=1), columns=[\"text\"])\n",
    "\n",
    "\n",
    "# y_true = test.sentiment\n",
    "# X_test = pd.DataFrame(test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
    "\n",
    "# train_data = Dataset.from_pandas(X_train)\n",
    "# eval_data = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177bcc57-df75-422a-ada8-e742aa737437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Assuming you have separate CSV files for train and test datasets\n",
    "train_filename = \"train.csv\"\n",
    "test_filename = \"test.csv\"\n",
    "\n",
    "# Read the train and test datasets\n",
    "train = pd.read_csv(train_filename, names=[\"sentiment\", \"text\", \"year\", \"id\"], encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "test = pd.read_csv(test_filename, names=[\"sentiment\", \"text\", \"year\", \"id\"], encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "\n",
    "# Split train dataset into train and validation sets\n",
    "train_data, eval_data = train_test_split(train, train_size=0.95, test_size=0.05, random_state=42)\n",
    "\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "             <INST>Consider yourself the meta reviewer of a conference. I will give you the review of a peer reviewer on a paper enclosed within <p> and </p>, and the  meta review of that particular review enclosed within <m> and </m>, that will carry the sentiment of the rating by the reviewer about that paper. Your job is to analyze both of them and output, whether the final decision of the reviwer on that paper will be Accept or Reject. Your output can be either Accept or Reject and no other text. No Revise or Resubmit. Do not print any extra text.Either Accept or Reject.</INST>\n",
    "            \n",
    "            [{data_point[\"text\"]}] = {data_point[\"sentiment\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point, test_year):\n",
    "    return f\"\"\"\n",
    "            <INST>Consider yourself the meta reviewer of a conference. I will give you the review of a peer reviewer on a paper enclosed within <p> and </p>, and the  meta review of that particular review enclosed within <m> and </m>, that will carry the sentiment of the rating by the reviewer about that paper. Your job is to analyze both of them and output, whether the final decision of the reviwer on that paper will be Accept or Reject. Your output can be either Accept or Reject and no other text. No Revise or Resubmit. Either Accept or Reject.</INST>\n",
    "\n",
    "            [{data_point[\"text\"]}] = \"\"\".strip()\n",
    "\n",
    "# Use train and test DataFrames as needed\n",
    "X_train = pd.DataFrame(train.apply(generate_prompt, axis=1), columns=[\"text\"])\n",
    "X_eval = pd.DataFrame(eval_data.apply(generate_prompt, axis=1), columns=[\"text\"])\n",
    "\n",
    "\n",
    "def filter_test_data(test_data, year):\n",
    "    if year == 0:\n",
    "        return test_data\n",
    "    else:\n",
    "        return test_data[test_data[\"year\"] == year]\n",
    "\n",
    "# Example usage: filter the test data for a specific year\n",
    "test_year = 2020\n",
    "filtered_test_data = filter_test_data(test, test_year)\n",
    "X_test = pd.DataFrame(filtered_test_data.apply(lambda x: generate_test_prompt(x, test_year), axis=1), columns=[\"text\"])\n",
    "\n",
    "# Generate y_true for the test dataset\n",
    "y_true = filtered_test_data[\"sentiment\"]\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7273c09d-f20e-4403-ac97-6342fc50a7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331    <INST>Consider yourself the meta reviewer of a...\n",
       "332    <INST>Consider yourself the meta reviewer of a...\n",
       "333    <INST>Consider yourself the meta reviewer of a...\n",
       "334    <INST>Consider yourself the meta reviewer of a...\n",
       "335    <INST>Consider yourself the meta reviewer of a...\n",
       "                             ...                        \n",
       "496    <INST>Consider yourself the meta reviewer of a...\n",
       "497    <INST>Consider yourself the meta reviewer of a...\n",
       "498    <INST>Consider yourself the meta reviewer of a...\n",
       "499    <INST>Consider yourself the meta reviewer of a...\n",
       "500    <INST>Consider yourself the meta reviewer of a...\n",
       "Name: text, Length: 170, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e18834-c005-44ce-bf91-d727bb1f4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Sudipta1995/Llama-2-7b-chat-finetuned-again\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a6d5c77-d064-4864-92d8-aaaea50e99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46348954-0c8e-4eea-ba39-eb0177c7625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4578334-6d89-4d98-8296-34f00da764ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 5\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 1\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 1\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "050c19fb-d2ce-478b-8fbe-792e7ceac3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec157b54-6b37-4c67-b60c-30bbed2dd08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba85bc8e-92aa-4f95-9447-c97fa4466695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8e90033-ee6c-4f65-a489-27965ef0dd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d85d819a1a4421996c717cb1de2b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 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\n",
    "\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bfeca07-afa0-4d50-8518-622dc5acc18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96029c96e5f848c7aac714be5be47555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2d279ee4664b7fbd0d2bb9c149daaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c97cb89b6b46168f00fc1a26e144ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bbafdb6bdf47259c106a6dd0d653b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ab885b2d3744ac9afe0620aff1280a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8013d2ca1444676a6ed78d55372dbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53fe05dade741288656cdef810e9348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "335a8f8f-9e2c-4d29-bb79-01a0281dacf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a788674e284455fb8ca4836c1cd4d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c588de62111c4cf29fe05d36d5691466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf9299b695f4891b085229a216dd235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46cb60ed-94ed-4c72-b097-23dfbc0166d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='Sudipta1995/Llama-2-7b-chat-finetuned-again', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False), 'pad_token': '</s>'}, clean_up_tokenization_spaces=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e4fc8be-a7a9-48da-bd43-ebf0273ad089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1ed6720-da8a-4c6f-b272-f87de16bb1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Assuming 'model' and 'tokenizer' are already defined\n",
    "\n",
    "def generate_text_from_query(query):\n",
    "    pipe = pipeline(task=\"text-generation\", \n",
    "                    model=model, \n",
    "                    tokenizer=tokenizer, \n",
    "                    max_new_tokens=30, \n",
    "                    temperature=0.4,\n",
    "                   )\n",
    "    result = pipe(query)\n",
    "    answer = result[0]['generated_text'].split(\"=\")[-1]\n",
    "    return answer\n",
    "\n",
    "# Example usage:\n",
    "custom_query = '''<INST>Consider yourself the meta reviewer of a conference. I will give you the review of a peer reviewer on a paper enclosed within <p> and </p>, and the  meta review of that particular review enclosed within <m> and </m>, that will carry the sentiment of the rating by the reviewer about that paper. Your job is to analyze both of them and output, whether the final decision of the reviwer on that paper will be Accept or Reject. Your output can be either Accept or Reject and no other text. No Revise or Resubmit. Do not print any extra text.Either Accept or Reject.</INST>'''\n",
    "reviews='''\n",
    "<p>Peer Review:   Summary:  The paper introduces a new benchmark which measures agent reasoning abilities and their generalization of 3 kinds: perceptual, conceptual and algorithmic. The paper extensively motivates this benchmark and shows experiments with training RL agents on it.       Reasons for score:  New benchmarks for measuring intelligence are important for driving the field. This one seems interesting.     Pros:  1. New benchmark which tries to provide a comprehensive measure of generalization, which is a very important topic. 2. Paper is nicely written and illustrated - pleasure to read! 3. Benchmark/code will be published upon acceptance, so the whole community will be able to profit from it.    Cons:  1. The history of artificial domains as AGI playgrounds has taught us a few bitter lessons. To give one very recent example, the winner of Abstraction and Reasoning Challenge (yeah, that one proposed by Francois Chollet to measure general intelligence https://arxiv.org/abs/1911.01547) wrote \"\"Unfortunately, I don't feel like my solution itself brings us closer to AGI.\"\" https://www.kaggle.com/c/abstraction-and-reasoning-challenge/discussion/154597. The solution was some handcrafted search algorithm, no machine learning. To be fair, the challenge is very far from being solved - and yet the winning solution from 914 teams didn't teach us much. Is there anything in the design of HALMA which we expect will protect it from similar problems?  2. No human baselines are given. How do we know that our agents achieved human performance?    Questions during rebuttal period:   I would be curious to know the authors' opinion on Cons above.    Minor suggestions and typos:   (1) affordnace -> affordance</p>\n",
    "<m>Meta Review: The paper presents a valuable contribution to the field with a new benchmark that evaluates agent reasoning abilities across various generalization types. The paper is well-written and provides a pleasant reading experience. Upon acceptance, the benchmark and code will be made available to the community, fostering progress and collaboration. However, some concerns arise regarding the potential limitations of artificial domains as AGI playgrounds, drawing from past experiences. Additionally, the absence of human baselines raises questions about the comparative performance of the agents. These points merit consideration, and addressing them could further strengthen the paper's conclusions and impact. Based on the available information, I recommend acceptance of this well-crafted and meaningful contribution.</m>\n",
    "'''\n",
    "\n",
    "generated_text = generate_text_from_query(custom_query+reviews)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebbe4ec4-c068-4e58-b961-5d36704f3c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/170 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1eSuSc9YS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/170 [00:01<04:03,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkek1NdX5r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/170 [00:02<03:55,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJl8qb66KS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/170 [00:04<03:52,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HkeJVOr0FH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/170 [00:05<03:45,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkeiA3I19H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/170 [00:07<03:52,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1lWqw86FS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 6/170 [00:08<03:57,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJgkW77MYH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 7/170 [00:09<03:50,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1xvdmZJ5B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 8/170 [00:11<03:48,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJgkmBE_uB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 9/170 [00:13<04:15,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skx2lGd6Kr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 10/170 [00:14<04:05,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byg6nlvaKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 11/170 [00:15<03:53,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syl5iFwiKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 12/170 [00:17<03:50,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BkeCLhJAtr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 13/170 [00:18<03:47,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJezXLYC5B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 14/170 [00:20<03:42,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1e4AYBAtB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 15/170 [00:23<05:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJgp2lKpYB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 16/170 [00:24<04:31,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1xod8Xe9S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 17/170 [00:26<04:10,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJe0aM3sYB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 18/170 [00:27<03:58,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BkeC2ghiFB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 19/170 [00:28<03:54,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJx8NdWaKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 20/170 [00:30<03:46,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJls05-ptS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 21/170 [00:31<03:35,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyxNjjojKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 22/170 [00:33<03:31,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJeltjbHcH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 23/170 [00:34<03:30,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJe9wpdScS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 24/170 [00:35<03:27,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyeDKG10KH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 25/170 [00:37<03:23,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BkewAg0n9r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 26/170 [00:38<03:26,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ryePl_e5Kr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 27/170 [00:40<03:20,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ryekKugcOr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 28/170 [00:41<03:31,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skx4JPuvYH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 29/170 [00:43<03:25,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkxiT9QatH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 30/170 [00:44<03:20,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJx2t271cB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 31/170 [00:45<03:13,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ryetcUV7iH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 32/170 [00:47<03:10,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SylWjepycS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 33/170 [00:48<03:08,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rJg7BzyAYS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 34/170 [00:49<03:08,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1erdj7CFB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 35/170 [00:51<03:06,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syxmdc1CKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 36/170 [00:52<03:04,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkgtBCT1YH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 37/170 [00:54<03:02,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1x7498kcS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 38/170 [00:55<03:02,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJxkVFSoKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 39/170 [00:56<03:02,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkeLO7hqFr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 40/170 [00:58<03:01,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SygCwHW0Fr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 41/170 [00:59<03:04,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rJl4tiBa9S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 42/170 [01:01<03:07,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ryeH-6BycH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 43/170 [01:02<03:04,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BkglFISTYS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 44/170 [01:04<03:04,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rJef0QxAKH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 45/170 [01:05<03:06,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BylifkEWqH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 46/170 [01:07<02:59,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1e_TZJS9H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 47/170 [01:08<02:55,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1gKDV-0Fr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 48/170 [01:09<02:52,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkxuEDryqr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 49/170 [01:11<02:47,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rJeCqcNIKr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 50/170 [01:12<02:45,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ryxMDGOKur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 51/170 [01:14<02:45,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJxHV7JPjB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 52/170 [01:15<02:42,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1xYhv5J5H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 53/170 [01:16<02:40,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SygftbOCKr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 54/170 [01:18<02:38,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJxEpgtGcS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 55/170 [01:19<02:46,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1eg3T6ZoS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 56/170 [01:21<02:45,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJlg5IHCFS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 57/170 [01:22<02:41,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJgVe1df9H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 58/170 [01:24<02:43,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJgtvXIzYB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 59/170 [01:25<02:40,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ByxhvaYpYr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 60/170 [01:27<02:42,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyejd9jotH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 61/170 [01:28<02:36,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1lQL-d6YH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 62/170 [01:29<02:37,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJlEdHcYqH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 63/170 [01:31<02:34,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyxOWBlB9B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 64/170 [01:32<02:37,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJl_1dRl5r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 65/170 [01:34<02:32,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rklrlliQjS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 66/170 [01:35<02:32,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HygAVxO3OH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 67/170 [01:37<02:28,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BkxpyxE79H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 68/170 [01:38<02:25,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJg8AR0-9H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 69/170 [01:39<02:21,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJgu9zzXtr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 70/170 [01:41<02:22,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1ggL7XhKS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 71/170 [01:42<02:17,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1g_3CFatr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 72/170 [01:44<02:17,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SylY2HN4tr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 73/170 [01:45<02:14,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyeJgpOAtS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 74/170 [01:46<02:14,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJg13QwHFH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 75/170 [01:48<02:15,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyeyXb4TFS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 76/170 [01:49<02:10,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BklwQSsJtH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 77/170 [01:50<02:07,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1gVz2MTtB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 78/170 [01:52<02:06,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sye2k-pntH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 79/170 [01:53<02:03,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HkeFR4ZTKS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 80/170 [01:55<02:05,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyJgzPCYr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 81/170 [01:56<02:06,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ryx8p2xW9B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 82/170 [01:58<02:08,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1lHXXRhtH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 83/170 [01:59<02:04,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SylGq_LxqB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 84/170 [02:00<02:02,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJgUtBvZqS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 85/170 [02:02<02:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkeFNhQucB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 86/170 [02:03<01:59,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1xDXRoc9r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 87/170 [02:05<01:54,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJxR53RhtS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 88/170 [02:06<01:54,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkxlbSepYB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 89/170 [02:07<01:51,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJxqaF2WqB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 90/170 [02:09<01:48,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkl_u9hhYH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 91/170 [02:10<01:51,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJgvIf2kcS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 92/170 [02:12<01:50,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1xFrZXx9S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 93/170 [02:13<01:49,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BkgbSpbaKH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 94/170 [02:14<01:45,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJepxs90tS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 95/170 [02:16<01:44,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hkg7fUDxFS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 96/170 [02:17<01:41,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkef5M0RtH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 97/170 [02:18<01:39,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJeCW-u0tS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 98/170 [02:20<01:40,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJx82Wa0YH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 99/170 [02:21<01:39,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJlZg2lpqH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 100/170 [02:23<01:37,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BkgA2mRnYS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 101/170 [02:24<01:36,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rygrmXsCtS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 102/170 [02:25<01:34,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJe8hCFWqB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 103/170 [02:27<01:34,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJgnuHj6KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 104/170 [02:28<01:32,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1lBy4S0tS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 105/170 [02:30<01:31,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1ldAbEpYS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 106/170 [02:31<01:28,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byx6q3uqtS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 107/170 [02:32<01:26,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HygbT3sqKH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 108/170 [02:34<01:23,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HkllzwGI5B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 109/170 [02:35<01:23,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rklNiq1rqr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 110/170 [02:37<01:23,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rJx-uYwaFS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 111/170 [02:38<01:22,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ryx1A71lqB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 112/170 [02:39<01:20,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkgSq-KstS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 113/170 [02:41<01:19,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rklqqtBhYB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 114/170 [02:42<01:20,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJlvetnpFH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 115/170 [02:44<01:16,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJxQie4LcS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 116/170 [02:45<01:15,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byx3w9ePqS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 117/170 [02:46<01:14,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1g0xR9CYH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 118/170 [02:48<01:13,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJe_zR1aYB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 119/170 [02:49<01:10,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1ljILl2FH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 120/170 [02:51<01:11,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skx4ZTo2YH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 121/170 [02:52<01:08,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BylAQBSCFS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 122/170 [02:53<01:06,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1lIrpy6YS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 123/170 [02:55<01:05,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJl3FmwTtS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 124/170 [02:56<01:02,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJxet-ByqH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 125/170 [02:57<01:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1llj41atS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 126/170 [02:59<01:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HkxX4zVCKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 127/170 [03:00<00:58,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkgRPJHRYr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 128/170 [03:01<00:56,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1l215DtFH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 129/170 [03:03<00:55,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1g40VNkcr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 130/170 [03:04<00:53,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HkxhvW1H5S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 131/170 [03:06<00:53,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJghIrYk9r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 132/170 [03:07<00:53,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BkxaWAkZ9S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 133/170 [03:08<00:52,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rJenyvF6YB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 134/170 [03:10<00:51,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJeu-JE2FB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 135/170 [03:11<00:49,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJegMJ0hKS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 136/170 [03:13<00:47,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bkx48mSRKS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 137/170 [03:14<00:46,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BkxP9JsX9H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 138/170 [03:16<00:46,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ryxfBzICtS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 139/170 [03:17<00:44,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ByxRzN_RKH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 140/170 [03:19<00:42,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BygIZGO3YS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 141/170 [03:20<00:40,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyedjL7pYH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 142/170 [03:21<00:39,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1e8e81ntS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 143/170 [03:23<00:41,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HylrvBHXqH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 144/170 [03:24<00:38,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sygqf-m0Fr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 145/170 [03:26<00:36,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1l4i1BCtB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 146/170 [03:27<00:34,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1gWD_G9Yr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 147/170 [03:29<00:32,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkeKKnRaKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 148/170 [03:30<00:31,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJxSed6qdB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 149/170 [03:31<00:29,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1x_eK-RYB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 150/170 [03:33<00:28,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ByeUgZT35r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 151/170 [03:34<00:26,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1xLuTzbcr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 152/170 [03:36<00:24,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJeESBliqS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 153/170 [03:37<00:23,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1ebnpXOnH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 154/170 [03:38<00:21,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyggGAw6YB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 155/170 [03:40<00:20,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJxJ0SuRtH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 156/170 [03:41<00:19,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bke6KMzcqr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 157/170 [03:42<00:18,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJlFXM9aKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 158/170 [03:44<00:17,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJgdqX8HKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 159/170 [03:45<00:16,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1lM4XHstB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 160/170 [03:47<00:14,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rJenP7R6FH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 161/170 [03:48<00:13,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rJgugNuaKH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 162/170 [03:50<00:11,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rJxFYm3TtB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 163/170 [03:51<00:09,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyxjcDWbcH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 164/170 [03:53<00:08,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJxnmgeCFr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 165/170 [03:54<00:07,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HJlLkIImYr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 166/170 [03:55<00:05,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rygLTFZ4YH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 167/170 [03:57<00:04,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BJlcBGi3cr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 168/170 [03:58<00:02,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BkgUEOWkqH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 169/170 [04:00<00:01,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkxQ9BYvKr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [04:01<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    prompt = X_test.iloc[i][\"text\"]\n",
    "    year = int(filtered_test_data.iloc[i][\"year\"])  # Convert year to integer\n",
    "    review_id = filtered_test_data.iloc[i][\"id\"]\n",
    "    pipe = pipeline(task=\"text-generation\", \n",
    "                    model=model, \n",
    "                    tokenizer=tokenizer, \n",
    "                    max_new_tokens=30, \n",
    "                    temperature=0.1,\n",
    "                   )\n",
    "    print(review_id)\n",
    "    result = pipe(prompt)\n",
    "    answer = result[0]['generated_text'].split(\"=\")[-1].strip()\n",
    "    y_pred.append(f'{answer}<d>{year}<d>{review_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c73a1cd-e192-4ff7-92da-5db83709c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "import csv\n",
    "with open('2020predictions.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    for prediction in y_pred:\n",
    "        parts = prediction.split('<d>')\n",
    "        writer.writerow([parts[0], parts[1], parts[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3298c9b0-256a-4a7b-9841-c75d4a0a6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbd808bd-cc6b-4541-a77c-bbb987614ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty VRAM\n",
    "# del model\n",
    "# del pipe\n",
    "# del trainer\n",
    "import gc\n",
    "gc.collect()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11d11b8d-d54e-447a-ab5f-ab5af5ff0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a01642b6-86cc-40da-a757-6d324b436002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accept. The paper presents a novel and robust approach for dense Structure-from-Motion using Deep Learning, with a clear explanation of the method<d>2019<d>r1x8O_Sw3X',\n",
       " 'Accept. The paper, while requiring revisions, offers a promising approach to solving the SfM problem by explicitly incorporating geometry priors into<d>2019<d>SylPHRPDnQ',\n",
       " 'Accept: The paper presents a novel and interesting approach to bundle adjustment, combining geometric optimization with deep learning. The authors propose a formulation that allows<d>2019<d>SJx-VMJcnm',\n",
       " 'Accept: The paper presents a novel approach for deterministic variational inference in feed-forward Bayesian Neural Networks, demonstrating its superiority<d>2019<d>H1eOIrXYhm',\n",
       " 'Accept: This paper presents a novel deterministic approach for learning variational posterior approximations in Bayesian neural networks, demonstrating originality and potential through<d>2019<d>H1g0a1ir2Q',\n",
       " 'Accept: The paper presents novel and potentially useful contributions to the field of VB applied to DNNs, with well-written content and a major technical<d>2019<d>rJexO5ZynQ',\n",
       " 'Accept: The paper presents a novel approach to integrating latent tree structure into RNN models, demonstrating promising results in unsupervised parsing<d>2019<d>BkgiNwT7h7',\n",
       " 'Accept: The paper presents a novel and original idea, with promising results on small datasets. The authors demonstrate a deep understanding of the subject matter through<d>2019<d>Bygp1Apv2m',\n",
       " 'Accept: The paper introduces an interesting approach to incorporating hierarchical inductive bias into LSTM architecture, with promising results in un<d>2019<d>H1ewsJDcjm',\n",
       " 'Accept: The paper presents significant advancements in image generation, leveraging the SAGAN approach and introducing a novel truncation trick. The<d>2019<d>SJl68_Hx37',\n",
       " 'Accept: The paper presents a thorough investigation of scaling GANs for complex datasets, demonstrating significant improvements in performance. The authors provide valuable insights<d>2019<d>S1gaWerP2X',\n",
       " 'Accept: The paper presents a well-motivated and well-justified suite of techniques for training large-scale GANs, yielding<d>2019<d>HklmZ1xqhm',\n",
       " 'Accept. This paper presents a novel approach to representation learning, Deep InfoMax (DIM), which maximizes the mutual information between the input and<d>2019<d>rkgBfaIahQ',\n",
       " 'Accept. The paper presents a novel approach to feature extraction, supported by robust empirical results. While some initial claims may have been overstated<d>2019<d>B1gEEtgAjm',\n",
       " 'Accept: The paper presents a novel representation learning approach, demonstrating strong performance in image classification tasks. The methodology is well-grounded and the<d>2019<d>BkxA0Kt3nQ',\n",
       " 'Accept: The paper presents a novel application of GANs in the context of the knockoff method, demonstrating improved performance in simulations. The authors<d>2019<d>H1eAulfwpm',\n",
       " 'Accept: The paper presents a novel extension of the knockoff framework, utilizing a GAN-based approach to address non-Gaussian feature distributions<d>2019<d>HklHlOUPnQ',\n",
       " 'Accept: This paper presents a novel feature selection method using GANs, demonstrating its effectiveness through a well-structured numerical study. The<d>2019<d>HkeTawVrhX',\n",
       " 'Accept: The paper presents a significant and innovative contribution to the field of protein structure prediction, with a well-designed Langevin-based<d>2019<d>SJlUZjqEim',\n",
       " 'Accept: The paper is well-written and presents a novel approach to energy functions and sequence shaping, with strong references to the relevant literature. The<d>2019<d>B1lRoQMLTX',\n",
       " 'Accept: The paper presents a novel end-to-end training framework for predicting protein structure from sequence, with several technical contributions. The reviewer<d>2019<d>Skx-IPBvTQ',\n",
       " 'Accept: The paper presents an intriguing approach for protein structure prediction, utilizing an end-to-end differentiable model. The authors provide<d>2019<d>Hkgk3b343m',\n",
       " 'Accept. The paper presents a novel approach to addressing the biases of ImageNet-trained CNNs, demonstrating a significant improvement in alignment<d>2019<d>rJlAnqlH2X',\n",
       " 'Accept: The paper presents a thorough empirical study of the texture bias in popular CNN models, providing valuable insights that can inform research in self-<d>2019<d>HJxSI4x527',\n",
       " 'Accept: The paper presents a clear and well-written analysis of the behavior bias between human and advanced CNN classifiers in object classification tasks. The experimental<d>2019<d>BkeaMFAK3m',\n",
       " 'Reject</INST>\\n\\n> Meta Review: The paper under review presents a novel and theoretically ground<d>2019<d>H1xPEJOVsm',\n",
       " 'Accept: The paper presents a novel approach to learning hierarchical embeddings, demonstrating improved performance on relevant benchmark datasets. The concept of converting<d>2019<d>rJglCnOshm',\n",
       " 'Accept: The paper presents a novel adaptation of the box lattice model, demonstrating improved performance on unbalanced data. The authors provide clear explanations<d>2019<d>SylZ79N5hm',\n",
       " \"Accept: The paper presents a novel application of random network analysis to deep autoencoders, providing valuable theoretical insights. The reviewer's<d>2019<d>B1lULFW9hm\",\n",
       " 'Accept: This paper presents a rigorous and innovative analysis of weighted tied auto-encoders, leveraging recent advancements in random<d>2019<d>SygkNeB92Q',\n",
       " 'Accept: The paper presents a novel perspective on the analysis of auto-encoders, with a clear and original approach. The authors provide a solid<d>2019<d>Skeq2IQ7h7',\n",
       " 'Accept: The paper presents a novel meta-learning approach that learns unsupervised learning rules for learning representations across different modalities, datasets, input<d>2019<d>SJeJvkj5hX',\n",
       " 'Accept: This paper introduces a novel meta-learning approach for unsupervised representation learning, demonstrating robust generalization performance across various base architectures<d>2019<d>Bkgckkbah7',\n",
       " 'Accept: The paper presents a novel approach to unsupervised learning, demonstrating competitive results and a clear, well-structured presentation. The<d>2019<d>r1eIOmju3m',\n",
       " 'Accept: The paper presents a novel meta-learning procedure, Leap, that demonstrates improved performance compared to existing alternatives. The reviewer acknowledges<d>2019<d>HJgKnIJY27',\n",
       " '<d>2019<d>Bkevhwv927',\n",
       " 'Accept: The paper presents a novel approach to a significant problem, with promising empirical results. The proposed method is well-explained and<d>2019<d>H1xWiy_q2Q',\n",
       " 'Accept: The paper presents a novel approach to learning long-range dependencies in images, demonstrating impressive results and contributing to the state-of<d>2019<d>HJgrrcCO2X',\n",
       " \"Accept. This paper presents a novel approach to density modeling, successfully demonstrating high-fidelity Imagenet samples. The reviewer'<d>2019<d>S1gjDP-927\",\n",
       " 'Accept: The paper presents a novel decoder architecture for image generation, demonstrating promising results and a clear methodology. While there are minor issues<d>2019<d>HkxN569T2X',\n",
       " 'Accept: The paper presents a novel approach to temporal difference learning in reinforcement learning, demonstrating promising results through four experiments. The reviewer<d>2019<d>rkeaQHUJam',\n",
       " 'Accept: The paper presents a novel approach to a significant problem in agent learning, and the proposed method is rigorously evaluated across four tasks, including<d>2019<d>rJeR1S-ThQ',\n",
       " 'Accept: The paper presents novel ideas and approaches, demonstrating a clear potential for advancement in the field. While there are areas that could benefit from<d>2019<d>BkgnEnawnm',\n",
       " 'Accept: The paper presents an interesting model of early visual representation, with a focus on shallow models and representation learning. The authors have made significant revis<d>2019<d>r1eiULeC3Q',\n",
       " 'Accept: This paper presents a well-structured and well-executed study that contributes to the field of computational neuroscience. The authors<d>2019<d>HJgMwJe5hm',\n",
       " 'Accept: The paper presents an innovative application of deep neural networks to a long-standing question in visual neuroscience, with a clear and well<d>2019<d>Hyg8wO1rhQ',\n",
       " 'Accept: The paper presents a novel approach to addressing content-based similarity in NL applications, offering a compelling alternative to self-attention<d>2019<d>H1glXkLRhm',\n",
       " 'Accept: The paper presents a novel approach to sequence modeling, offering significant advances over existing depthwise convolution sequence models. The authors provide a thorough<d>2019<d>H1gJoj8C3X',\n",
       " 'Accept: The paper presents a compelling alternative to self-attention in NLP tasks, demonstrating competitive performance and a significant reduction in parameters<d>2019<d>Byx0nlaKnX',\n",
       " 'Accept: The paper presents a well-engineered and well-described dataset, and the results are impressive, outperforming the current state<d>2019<d>BJl9uwaQ67',\n",
       " 'Accept: The paper presents a novel approach to generating piano music using neural networks, addressing the challenge of modeling multiple levels of music. The authors<d>2019<d>B1efz6dgpX',\n",
       " 'Accept: The paper presents a novel approach to piano music modeling, combining state-of-the-art models and a shared piano-roll representation<d>2019<d>S1gnFxZjnX',\n",
       " 'Accept: The paper presents a novel approach to improving memory-writing in memory augmented neural networks, with a strong theoretical foundation and clear presentation of<d>2019<d>SygH6Dzjpm',\n",
       " 'Accept. The paper introduces a novel algorithm for Memory Augmented Neural Networks, demonstrating potential in managing memory updates. The authors<d>2019<d>BJxv6enuhm',\n",
       " 'Accept. The paper is well-written, provides a clear contribution, and has the potential to impact the field. The authors are encouraged to address<d>2019<d>rJeuIPUjnm',\n",
       " 'Accept: The paper presents a novel approach to domain generalization, combining CNN-based discriminative feature extraction and gray level co-occurrence<d>2019<d>rJxbWynhhm',\n",
       " 'Accept: The paper presents an interesting unsupervised method for identifying superficial features, which is a valuable contribution to the field. The proposed<d>2019<d>H1ehlWduhm',\n",
       " 'Accept: The paper is well-structured and well-written, with a clear and original approach to addressing the domain generalization challenge. The<d>2019<d>HJee7cfwh7',\n",
       " 'Accept: The paper presents a novel solution to address security challenges in cloud-based Machine Learning models, demonstrating both technical merit and clear presentation<d>2019<d>rkgtvmXc2m',\n",
       " 'Accept: The paper presents a novel and effective method for securely evaluating neural networks, with strong results and thorough experimentation. The approach is well<d>2019<d>r1eyl4tHhQ',\n",
       " 'Accept: The paper presents a novel and promising approach to building trustworthy and privacy-protecting AI systems, with a clear<d>2019<d>HJg2YxyGoQ',\n",
       " 'Accept: The paper presents a novel approach to visual reasoning using object-based representations and a differentiable quasi-symbolic executor. The authors demonstrate<d>2019<d>r1g6tF8F3X',\n",
       " 'Accept: The paper presents an interesting approach to jointly learn visual representation and semantic parsing of sentences using a neuro-symbolic concept learner and<d>2019<d>HJeHGTF5nX',\n",
       " 'Accept: The paper is well-written and demonstrates a strong understanding of the topic, with constructive feedback provided by the reviewer to enhance<d>2019<d>Sklo1V_znQ',\n",
       " 'Deny\\n\\nPlease choose<d>2019<d>Bkg5UpU52m',\n",
       " 'Accept. The paper presents a thorough investigation of the lottery ticket hypothesis, demonstrating the existence of winning tickets within randomly initialized neural networks. The<d>2019<d>ryemP68v2m',\n",
       " \"Accept with minor revisions. The paper presents a valuable contribution to the field of generative modeling, and the authors' responses address the concerns raised<d>2019<d>HklkaJG92m\",\n",
       " 'Accept: The paper presents a novel application of ODE solvers to continuous normalizing flow, demonstrating improved performance and a deeper neural network architecture.<d>2019<d>Hylm9LQd3X',\n",
       " \"Accept: The paper presents a novel technique for continuous normalization flow, offering a more efficient approach to log density estimation. The authors' contribution is significant<d>2019<d>ryeYYxV9n7\",\n",
       " 'Accept: The paper presents a thorough investigation of the expressive power of neighborhood aggregation mechanisms in Graph Neural Networks, with a particular focus<d>2019<d>HJgMSgUqhQ',\n",
       " 'Accept. The paper presents an innovative perspective on Weisfeiler-Lehman-type GNNs, offering valuable insights and propos<d>2019<d>rkeW9FDnnQ',\n",
       " 'Reject</INST>\\n\\n> Accept</p>\\n\\np> The review highlights the novel<d>2019<d>BJgIGNTP27',\n",
       " 'Accept: The paper presents a novel and original approach to learning across mixed graph topologies, utilizing a unified framework for handling differing graph top<d>2019<d>BJxMFSeonm',\n",
       " 'Accept: The paper presents a novel extension of cycle-consistent adversarial adaptation methods for domain adaptation, showing effectiveness in both low-resource super<d>2019<d>rkgVnNv52Q',\n",
       " '<d>2019<d>HklKo3NW6Q',\n",
       " 'Accept: The paper presents a thorough analysis of variational dropout methods, particularly the mean propagation at test time and the effect of weight variance in<d>2019<d>SkxrImCK2Q',\n",
       " 'Accept: The paper is well-written, clearly presenting the study of variance neural networks and their optimization. The reviewer appreciates the solid technique<d>2019<d>r1e0vhrKhX',\n",
       " \"Accept: The paper presents a novel stochastic layer, variance layer, and demonstrates its competitive performance in various tasks. The reviewer's<d>2019<d>HygV2aqO3Q\",\n",
       " \"Accept. The paper presents a novel improvement on equilibrium propagation, with a clear theoretical contribution and promising practical implications. The reviewer's<d>2019<d>ryeI_q3v3Q\",\n",
       " 'Accept: The paper presents a novel extension to Equilibrium Propagation, demonstrating improved run-time through the use of a separate feedforward<d>2019<d>r1eOy7xKhQ',\n",
       " 'Accept: The paper presents innovative methodologies and thoughtful comparisons, demonstrating a strong understanding of the domain and a solid contribution to the field<d>2019<d>SklSwVYo37',\n",
       " 'Accept. The paper presents an interesting and surprising method for salient weight selection, utilizing a novel multiplicative sensitivity measure. The reviewer<d>2019<d>r1ecBMxwTm',\n",
       " 'Accept: The paper presents a novel approach to pruning neural network weights, backed by thorough experimental evaluation. While the concept of using the gradient as<d>2019<d>Bygrtyec3X',\n",
       " 'Accept: The paper presents a novel approach to neural network pruning, with a clear and well-written presentation. The proposed method demonstrates promising<d>2019<d>Hkx-JZ3vh7',\n",
       " 'Reject: The paper proposes a two-stage VAE method, but lacks clarity in certain areas. The rationale behind the second<d>2019<d>Bkg4rgm93Q',\n",
       " \"Accept: The paper presents a novel two-stage VAE approach with valuable mathematical insights and potential contributions to the machine learning community. The authors'<d>2019<d>HJxVsagYnm\",\n",
       " 'Accept. The paper presents novel theoretical contributions and a promising new algorithm, demonstrating significant improvements in sample quality and closing the gap between Gaussian VA<d>2019<d>Bye1QOek6m',\n",
       " 'Accept: The paper presents a novel and interesting approach to cross-modality matching, with promising results and clear explanations. While there are minor<d>2019<d>r1e5d52hhQ',\n",
       " 'Accept: The paper presents a novel approach to cross-modal matching, leveraging deep learning techniques and a modality-agnostic classifier. The experimental<d>2019<d>Hkxxm_Qsh7',\n",
       " \"Accept: The paper presents a novel method for matching people's voices to their facial images, showing robust performance across various evaluations. The proposed<d>2019<d>HkxvRZesnQ\",\n",
       " 'Accept: The paper presents an innovative approach to learning a function from typed input-output data, utilizing analogy and subfunctions learned by an<d>2019<d>r1gbHlap3X',\n",
       " 'Accept: The review paper presents a thorough examination of recent research in learned representations with complex structure, with thought-provoking questions that could lead to<d>2019<d>BJl1SmLj3m',\n",
       " 'Accept. The paper presents a novel approach to solving problems with compositional and recursive structure, and the proposed Compositional Recursive Learner (CRL<d>2019<d>B1eifeX9n7',\n",
       " 'Reject</INST>\\n\\n> Resubmit</INST>\\n\\n> Retain</INST><d>2019<d>SJgyyPTv3m',\n",
       " 'Accept: The paper presents a novel multi-task learning approach for VQA, demonstrating improved performance on certain tasks. The authors provide a clear<d>2019<d>H1gUmqkh3Q',\n",
       " 'Accept: The paper presents a novel approach to VQA tasks, utilizing task-level modules and providing a clear organization, detailed description, and<d>2019<d>r1eaptK5hm',\n",
       " 'Accept. The paper presents a significant theoretical contribution, establishing a connection between Bayesian CNN and Gaussian processes, and provides extensive experimental comparison to support their<d>2019<d>SygaK6RU14',\n",
       " 'Retract</<d>2019<d>BkxQiXRYhX']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30219be0-e0bf-47e3-a004-a495a6da1ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
